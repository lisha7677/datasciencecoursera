---
title: "Data Science Capstone Week 2"
author: "Sha Li"
date: "7/29/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(tm)
library(ngram)
library(textcat)
```
#### read in training set.
```{r}
training<-readLines('training.txt', encoding = 'UTF-8', skipNul = TRUE)
```
#### Profanity filtering - removing profane words that shouldn't be predicted.
```{r}
profanity<-read.table('http://www.bannedwordlist.com/lists/swearWords.txt')
```
#### Convert all words to lower case, remove punctuation, remove numbers, remove extra spacing, there is no need to remove stop words because they are the necessary component of the syntax. 815 is the longest line.
```{r}
corpora<-unlist(strsplit(training, '\\.|\\?|\\!|\\:|\\,|\\;'))
corpora<-removeNumbers(corpora)
corpora<-removePunctuation(corpora)
corpora<-tolower(corpora)
corpora<-removeWords(corpora,as.character(profanity[c(-37:-40, -72),1]))
corpora<-stripWhitespace(corpora)
corpora<-trimws(corpora)
```
#### Tokenization
```{r}
uniCorpora<-corpora[sapply(strsplit(corpora, ' '), length) > 0]
uniToken <- ngram(uniCorpora, n = 1)
biCorpora<-corpora[sapply(strsplit(corpora, ' '), length) > 1]
biToken <- ngram(biCorpora, n = 2)
triCorpora<-corpora[sapply(strsplit(corpora, ' '), length) > 2]
triToken <- ngram(triCorpora, n = 3)
```
#### Understand frequencies of words and word pairs - build figures and tables to understand variation in the frequencies of words and word pairs in the data. Print top 10 most frequent word or words in unigrams, bigrams, trigrams, and quadgrams.
```{r}
unigram <- get.phrasetable(uniToken)
bigram <- get.phrasetable(biToken)
trigram <- get.phrasetable(triToken)
```
#### build bigram model, remove words with few counts from corpus
```{r}
bigramS<-data.frame(do.call('rbind', strsplit(bigram$ngrams, ' ', fixed = TRUE)), bigram$freq, stringsAsFactors = FALSE)

biN<-bigramS[bigramS$bigram.freq>=10,]

biRow<-unique(biN$X1)
biCol<-unique(biN$X2)

Sys.time()
biMatrix<-matrix(NA, nrow = length(biRow), ncol = length(biCol), dimnames = list(biRow, biCol))
for (i in 1:nrow(biN)) {
  biMatrix[rownames(biMatrix) == biN[i,1], colnames(biMatrix) == biN[i,2]]<-biN[i,3]
}
Sys.time()

biA<-sapply(biRow, function(x) {sum(bigramS[bigramS$X1==x, 3])})
biB<-sapply(biCol, function(x) {sum(bigramS[bigramS$X2==x, 3])})
biC<-rowSums(biMatrix, na.rm = TRUE)
biD<-colSums(biMatrix, na.rm = TRUE)

biRowUNK<-biA-bic
biColUNK<-c(biB-biD, NA)

biMatrixUNK<-rbind(cbind(biMatrix, unk = biRowUNK), unk = biColUNK)

biProp<-biMatrixUNK/rowSums(biMatrixUNK, na.rm = TRUE)
```
#### build trigram model, remove words with few counts from corpus
```{r}
trigramSplit<-data.frame(do.call('rbind', strsplit(trigram$ngrams, ' ', fixed = TRUE)), trigram$freq, stringsAsFactors = FALSE)
trigramS<-cbind.data.frame(X1 = paste(trigramSplit$X1, trigramSplit$X2), X2 = trigramSplit$X3, trigram.freq = trigramSplit$trigram.freq)

triN<-trigramS[trigramS$trigram.freq>=10,]

triRow<-unique(triN$X1)
triCol<-unique(triN$X2)

Sys.time()
triMatrix<-matrix(NA, nrow = length(triRow), ncol = length(triCol), dimnames = list(triRow, triCol))
for (i in 1:nrow(triN)) {
  triMatrix[rownames(triMatrix) == triN[i,1], colnames(triMatrix) == triN[i,2]]<-triN[i,3]
}
Sys.time()

triA<-sapply(triRow, function(x) {sum(trigramS[trigramS$X1==x, 3])})
triB<-sapply(triCol, function(x) {sum(trigramS[trigramS$X2==x, 3])})
triC<-rowSums(triMatrix, na.rm = TRUE)
triD<-colSums(triMatrix, na.rm = TRUE)

triRowUNK<-triA-triC
triColUNK<-c(triB-triD, NA)

triMatrixUNK<-rbind(cbind(triMatrix, unk = triRowUNK), unk = triColUNK)

triProp<-triMatrixUNK/rowSums(triMatrixUNK, na.rm = TRUE)
```
